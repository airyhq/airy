{{ if eq .Values.global.kubernetes.appImageTag "0.29.0"}}
# Helper scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: upgrade-{{ .Values.global.kubernetes.appImageTag }}
  namespace: {{ .Values.global.kubernetes.namespace }}
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-weight": "1"
  labels:
    core.airy.co/upgrade: "true"
data:
  check-existing-wehook.sh: |
    #!/bin/sh
    system_token=${SYSTEM_TOKEN}
    curl -X POST -H "Content-Type: application/json" -H "Authorization: Bearer ${system_token}" api-admin/webhooks.info -w "\n%{http_code}\n" > /tmp/response.txt
    cat /tmp/response.txt
    status_code=$(cat /tmp/response.txt | tail -n 1)
    if [ "${status_code}" = "404" ]; then
        kubectl patch configmap upgrade-{{ .Values.global.kubernetes.appImageTag }} --type merge -p '{"data":{"webhookUsed": "false"}}'
    else
      if [ "${status_code}" = "200" ]; then
        webhooks=$(cat /tmp/response.txt | head -n 1)
        if [ -z "${webhooks}" ]; then
          kubectl patch configmap upgrade-{{ .Values.global.kubernetes.appImageTag }} --type merge -p '{"data":{"webhookUsed": "false"}}'
        else
          kubectl patch configmap upgrade-{{ .Values.global.kubernetes.appImageTag }} --type merge -p '{"data":{"webhookUsed": "true"}}'
          echo ${webhooks} > /tmp/webhooks.yaml
          kubectl delete configmap existing-webhooks
          sleep 1
          kubectl create configmap existing-webhooks --from-file=/tmp/webhooks.yaml
          kubectl label configmap existing-webhooks core.airy.co/upgrade="true"
        fi
      fi
    fi

  subscribe-wehoook.sh: |
    #!/bin/sh
    system_token=${SYSTEM_TOKEN}
    webhookUsed=$(kubectl get configmap upgrade-{{ .Values.global.kubernetes.appImageTag }} -o jsonpath='{.data.webhookUsed}')
    echo "Webhook used: ${webhookUsed}"
    if [ "${webhookUsed}" = "true" ]; then
      request=$(kubectl get configmap existing-webhooks -o jsonpath='{.data.webhooks\.yaml}')
      curl -X POST -H "Content-Type: application/json" -H "Authorization: Bearer ${system_token}" -d "${request}" api-admin/webhooks.subscribe
    fi
---
# Cleanup old jobs
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.global.kubernetes.appImageTag }}-cleanup-upgrade
  namespace: {{ .Values.global.kubernetes.namespace }}
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-weight": "0"
  labels:
    core.airy.co/upgrade: "true"
spec:
  ttlSecondsAfterFinished: 120
  template:
    spec:
      containers:
      - name: reset-app
        image: "bitnami/kubectl"
        command: ['/bin/sh', '/opt/provisioning/upgrade-cleanup.sh']
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      serviceAccountName: airy-upgrade
      volumes:
        - name: upgrading-scripts
          configMap:
            name: upgrading-scripts
      restartPolicy: Never
  backoffLimit: 3
---
# Migrate api-communication
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.global.kubernetes.appImageTag }}-upgrade-api-communication
  namespace: {{ .Values.global.kubernetes.namespace }}
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-weight": "9"
  labels:
    core.airy.co/upgrade: "true"
spec:
  ttlSecondsAfterFinished: 120
  template:
    spec:
      initContainers:
      - name: scale-down
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/scale-down-deployment.sh']
        env:
        - name: DEPLOYMENT_NAME
          value: api-communication
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      - name: wait-consumer-group
        image: "{{ .Values.kafkaImage }}:{{ .Values.kafkaImageTag }}"
        command:  ['/bin/sh', '/opt/provisioning/wait-for-empty-consumer-group.sh']
        env:
        - name: KAFKA_BROKERS
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: KAFKA_BROKERS
        - name: CONSUMER_GROUP
          value: api.CommunicationStores
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      containers:
      - name: reset-app
        image: "{{ .Values.kafkaImage }}:{{ .Values.kafkaImageTag }}"
        command: ['/bin/sh', '/opt/provisioning/reset-streaming-app.sh']
        env:
        - name: KAFKA_BROKERS
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: KAFKA_BROKERS
        - name: INPUT_TOPICS
          value: 'application.communication.channels,application.communication.messages,application.communication.metadata,application.communication.read-receipt'
        - name: CONSUMER_GROUP
          value: api.CommunicationStores
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      serviceAccountName: airy-upgrade
      volumes:
        - name: upgrading-scripts
          configMap:
            name: upgrading-scripts
        - name: kafka-config
          configMap:
            name: kafka-config
      restartPolicy: Never
  backoffLimit: 3
---
# Migrate webhooks
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.global.kubernetes.appImageTag }}-upgrade-integration-webhooks
  namespace: {{ .Values.global.kubernetes.namespace }}
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-weight": "10"
  labels:
    core.airy.co/upgrade: "true"
spec:
  ttlSecondsAfterFinished: 120
  template:
    spec:
      initContainers:
      - name: wait-api-admin
        image: busybox
        command: ["/bin/sh", "/opt/provisioning/wait-for-service.sh"]
        env:
        - name: SERVICE_NAME
          value: api-admin
        - name: SERVICE_PORT
          value: "80"
        volumeMounts:
        - name: provisioning-scripts
          mountPath: /opt/provisioning
      - name: check-webhook
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/check-existing-wehook.sh']
        envFrom:
        - configMapRef:
            name: security
        volumeMounts:
        - name: upgrade
          mountPath: /opt/provisioning
      - name: scale-down-consumer
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/scale-down-deployment.sh']
        env:
        - name: DEPLOYMENT_NAME
          value: webhook-consumer
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      - name: scale-down-publisher
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/scale-down-deployment.sh']
        env:
        - name: DEPLOYMENT_NAME
          value: webhook-publisher
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      - name: scale-down-beanstalkd
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/scale-down-statefulset.sh']
        env:
        - name: STATEFULSET_NAME
          value: beanstalkd
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      - name: delete-pvc
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/delete-pvc.sh']
        env:
        - name: APP_LABEL
          value: beanstalkd
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      - name: create-topics
        image: "{{ .Values.kafkaImage }}:{{ .Values.kafkaImageTag }}"
        command: ["/bin/sh", "/opt/provisioning/create-topics.sh"]
        env:
        - name: ZOOKEEPER
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: ZOOKEEPER
        - name: REPLICAS
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: KAFKA_MINIMUM_REPLICAS
        volumeMounts:
        - name: kafka-create-topics
          mountPath: /opt/provisioning
      - name: wait-consumer-group
        image: "{{ .Values.kafkaImage }}:{{ .Values.kafkaImageTag }}"
        command:  ['/bin/sh', '/opt/provisioning/wait-for-empty-consumer-group.sh']
        env:
        - name: KAFKA_BROKERS
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: KAFKA_BROKERS
        - name: CONSUMER_GROUP
          value: webhook.Publisher
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      containers:
      - name: reset-app
        image: "{{ .Values.kafkaImage }}:{{ .Values.kafkaImageTag }}"
        command: ['/bin/sh', '/opt/provisioning/reset-streaming-app.sh']
        env:
        - name: KAFKA_BROKERS
          valueFrom:
            configMapKeyRef:
              name: kafka-config
              key: KAFKA_BROKERS
        - name: INPUT_TOPICS
          value: 'application.communication.messages,application.communication.metadata,application.communication.webhooks'
        - name: CONSUMER_GROUP
          value: webhook.Publisher
        volumeMounts:
        - name: upgrading-scripts
          mountPath: /opt/provisioning
      serviceAccountName: airy-upgrade
      volumes:
        - name: provisioning-scripts
          configMap:
            name: provisioning-scripts
        - name: upgrading-scripts
          configMap:
            name: upgrading-scripts
        - name: kafka-config
          configMap:
            name: kafka-config
        - name: kafka-create-topics
          configMap:
            name: kafka-create-topics
        - name: security
          configMap:
            name: security
        - name: upgrade
          configMap:
            name: upgrade-{{ .Values.global.kubernetes.appImageTag }}
      restartPolicy: Never
  backoffLimit: 3
---
# Subscribe webhook
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.global.kubernetes.appImageTag }}-post-upgrade
  namespace: {{ .Values.global.kubernetes.namespace }}
  annotations:
    "helm.sh/hook": "post-upgrade"
    "helm.sh/hook-weight": "10"
  labels:
    core.airy.co/upgrade: "post-upgrade"
spec:
  ttlSecondsAfterFinished: 120
  template:
    spec:
      initContainers:
      - name: wait-api-admin
        image: busybox
        command: ["/bin/sh", "/opt/provisioning/wait-for-service.sh"]
        env:
        - name: SERVICE_NAME
          value: api-admin
        - name: SERVICE_PORT
          value: "80"
        volumeMounts:
        - name: provisioning-scripts
          mountPath: /opt/provisioning
      containers:
      - name: subscribe-webhook
        image: bitnami/kubectl
        command:  ['/bin/sh', '/opt/provisioning/subscribe-wehoook.sh']
        envFrom:
        - configMapRef:
            name: security
        volumeMounts:
        - name: upgrade
          mountPath: /opt/provisioning
      serviceAccountName: airy-upgrade
      volumes:
        - name: provisioning-scripts
          configMap:
            name: provisioning-scripts
        - name: upgrading-scripts
          configMap:
            name: upgrading-scripts
        - name: kafka-config
          configMap:
            name: kafka-config
        - name: upgrade
          configMap:
            name: upgrade-{{ .Values.global.kubernetes.appImageTag }}
        - name: security
          configMap:
            name: security
      restartPolicy: Never
  backoffLimit: 3
{{ end }}
